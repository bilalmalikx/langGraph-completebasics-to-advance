{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f609160",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import langchain_anthropic. Please install with `pip install -U langchain-anthropic`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m tool_node = ToolNode([get_weather])\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Bind tool to LLM model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-5-haiku-latest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m model_with_tools = model.bind_tools([get_weather])\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Define state schema for messages\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/langchain-env/lib/python3.11/site-packages/langchain/chat_models/base.py:324\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m     warnings.warn(\n\u001b[32m    317\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    318\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    320\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    321\u001b[39m     )\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    330\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/langchain-env/lib/python3.11/site-packages/langchain/chat_models/base.py:353\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatOpenAI(model=model, **kwargs)\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33manthropic\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     \u001b[43m_check_pkg\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlangchain_anthropic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_anthropic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatAnthropic\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatAnthropic(model=model, **kwargs)  \u001b[38;5;66;03m# type: ignore[call-arg,unused-ignore]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/langchain-env/lib/python3.11/site-packages/langchain/chat_models/base.py:543\u001b[39m, in \u001b[36m_check_pkg\u001b[39m\u001b[34m(pkg, pkg_kebab)\u001b[39m\n\u001b[32m    539\u001b[39m pkg_kebab = pkg_kebab \u001b[38;5;28;01mif\u001b[39;00m pkg_kebab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pkg.replace(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    540\u001b[39m msg = (\n\u001b[32m    541\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Please install with `pip install -U \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg_kebab\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    542\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n",
      "\u001b[31mImportError\u001b[39m: Unable to import langchain_anthropic. Please install with `pip install -U langchain-anthropic`"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "#  Define a tool with @tool decorator\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Return a mock weather forecast for a given location.\"\"\"\n",
    "    if location.lower() in [\"sf\", \"san francisco\"]:\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "# Initialize ToolNode with the tool\n",
    "tool_node = ToolNode([get_weather])\n",
    "\n",
    "# Bind tool to LLM model\n",
    "model = init_chat_model(model=\"claude-3-5-haiku-latest\")\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "# Define state schema for messages\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list\n",
    "\n",
    "# Define agent node function\n",
    "def call_model(state: MessagesState) -> MessagesState:\n",
    "    response = model_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Function to check if model asked for tool usage\n",
    "def should_continue(state: MessagesState):\n",
    "    last = state[\"messages\"][-1]\n",
    "    if getattr(last, \"tool_calls\", None):\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# Build the state graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"agent\", call_model)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_edge(START, \"agent\")\n",
    "builder.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "result = graph.invoke({\"messages\":[{\"role\":\"user\",\"content\":\"what's the weather in SF?\"}]})\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
